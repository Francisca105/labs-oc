{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is the cache capacity of the computer you used (please write the workstation name)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "memo_num_accesses = {}\n",
    "\n",
    "\n",
    "def num_accesses(array_size):\n",
    "    \"\"\"Array size in KiB\"\"\"\n",
    "\n",
    "    key = array_size\n",
    "    if key in memo_num_accesses:\n",
    "        return memo_num_accesses[key]\n",
    "\n",
    "    array_size = array_size << 10\n",
    "\n",
    "    N_REPETITIONS = 100\n",
    "\n",
    "    STRIDE_MAX = 2\n",
    "\n",
    "    counter = 0\n",
    "    stride = 1\n",
    "\n",
    "    for stride in range(1, STRIDE_MAX, stride):\n",
    "\n",
    "        limit = array_size - stride + 1\n",
    "\n",
    "        for repeat in range(0, N_REPETITIONS * stride):\n",
    "            counter += (limit - 0) / stride\n",
    "\n",
    "    counter = int(counter)\n",
    "    memo_num_accesses[key] = counter\n",
    "\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(10):\n",
    "    df = pd.concat((df, pd.read_csv(f\"./data/spark{i:0>2}.tsv\", delimiter=\"\\t\")))\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = df.groupby([\"size\"], as_index=False).mean().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg[\"accesses\"] = df_avg[\"size\"].apply(lambda x: num_accesses(x >> 10))\n",
    "df_avg[\"mean_access_time\"] = df_avg[\"elapsed(s)\"] / df_avg[\"accesses\"]\n",
    "df_avg[\"mean_access_time (ns)\"] = df_avg[\"mean_access_time\"].apply(\n",
    "    lambda x: x * 10**9\n",
    ")\n",
    "df_avg[\"size (KiB)\"] = df_avg[\"size\"].apply(lambda x: x >> 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.sort_values(\"size\")[\n",
    "    [\"size (KiB)\", \"elapsed(s)\", \"accesses\", \"mean_access_time (ns)\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon analyzing the table above, which presents data collected from running the Spark program on the lab6p8 computer, we can determine that the cache capacity is 32KiB. This conclusion arises from the observation that the mean access time remains relatively constant for array sizes up to 32KiB (inclusive). However, once we reach 64KiB, the mean access time increases, suggesting a rise in the miss rate due to the L1 cache being filled. Consequently, it becomes clear that array sizes exceeding 32KiB no longer fit within the cache, resulting in longer access times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is the cache capacity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1 shows two groups of array sizes based on cache access times: one around 375 ns and the other around 500 ns. The first group likely includes arrays of size less than or equal to the cache capacity, indicating that these arrays can fully reside in the cache, resulting in lower access times. In contrast, the second group experiences higher execution times due to increased miss penalties as the arrays exceed cache capacity.\n",
    "\n",
    "The spike in reading and writing times beyond 64 KB confirms that this is the cache size limit, with the increase between 64 KB and 128 KB reflecting higher capacity misses. Thus, we conclude that the cache capacity corresponds to the maximum array size in the lower access time group: 64 KiB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the size of each cache block?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of a cache block can be determined by identifying the first stride where the access time stabilizes for the array sizes that do not fully fit in the cache (greater than 64 KB). We observe that the access time remains consistent for strides of 16 Bytes or larger, indicating that each accessed element corresponds to distinct cache blocks, resulting in a near 100% miss rate. Therefore, we can conclude that each cache block has a size of 16 Bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the L1 cache miss penalty time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the L1 cache miss penalty time, we compare the total execution times for different array sizes and access patterns. \n",
    "For array sizes that are smaller than the cache size, the miss rate is nearly 0%, resulting in an access time of approximately 375 ns. \n",
    "For larger arrays with a stride of 16 Bytes or greater, the access time increases to around 975 ns due to a nearly 100% miss rate.\n",
    "\n",
    "Therefore, the miss penalty can be determined by subtracting the lower access time from the higher one: 975 ns - 375 ns = 600 ns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3  Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Modeling the L1 Data Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What are the processor events that will be analyzed during its execution? Explain their meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the program's execution, the analyzed events will be L1 cache misses, which occur when data is not found in the L1 cache and access to the next memory level (L2 cache or main memory) is required. The cm1.c program tracks the PAPI_L1_DCM event, indicating \"L1 Data Cache Misses\". This analysis aims to quantify how often we attempt to retrieve data absent from the L1 cache throughout the program's runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Plot the variation of the average number of misses (Avg Misses) with the stride size, for each considered dimension of the L1 data cache (8kB, 16kB, 32kB and 64kB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_labels(val):\n",
    "    value = val.split(\"=\")[1]\n",
    "    return float(value) if \".\" in value else int(value)\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(10):\n",
    "    df = pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            pd.read_csv(\n",
    "                f\"./data/cm1_l1_{i:0>2}.tsv\",\n",
    "                delimiter=\"\\t\",\n",
    "                names=[\"cache_size\", \"stride\", \"avg_misses\", \"avg_time\"],\n",
    "                converters={\n",
    "                    \"cache_size\": strip_labels,\n",
    "                    \"stride\": strip_labels,\n",
    "                    \"avg_misses\": strip_labels,\n",
    "                    \"avg_time\": strip_labels,\n",
    "                },\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = (\n",
    "    df.groupby([\"cache_size\", \"stride\"], as_index=False).median().drop(\"index\", axis=1)\n",
    ")\n",
    "\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drawSvg as draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = draw.Drawing(300, 320)\n",
    "\n",
    "for y, i in zip(range(310, 40, -10), range(0, 27)):\n",
    "    d.append(\n",
    "        draw.Text(\n",
    "            f\"{df_avg['avg_misses'][i]:.6f}\", 8, 0, y, style=\"font-family: 'monospace'\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "for y, i in zip(range(310, 40, -10), range(0, 27)):\n",
    "    d.append(\n",
    "        draw.Text(\n",
    "            f\"{df_avg['avg_time'][i]:.6f}\",\n",
    "            8,\n",
    "            0 + 50,\n",
    "            y,\n",
    "            style=\"font-family: 'monospace'\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "for y, i in zip(range(310, 0, -10), range(27, 58)):\n",
    "    d.append(\n",
    "        draw.Text(\n",
    "            f\"{df_avg['avg_misses'][i]:.6f}\",\n",
    "            8,\n",
    "            183,\n",
    "            y,\n",
    "            style=\"font-family: 'monospace'\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "for y, i in zip(range(310, 0, -10), range(27, 58)):\n",
    "    d.append(\n",
    "        draw.Text(\n",
    "            f\"{df_avg['avg_time'][i]:.6f}\",\n",
    "            8,\n",
    "            183 + 50,\n",
    "            y,\n",
    "            style=\"font-family: 'monospace'\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "d.setPixelScale(1.76)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "sns.set_theme(context=\"poster\", style=\"whitegrid\")\n",
    "\n",
    "g_results = sns.lineplot(\n",
    "    data=df_avg, x=\"stride\", y=\"avg_misses\", hue=\"cache_size\", palette=\"deep\"\n",
    ")\n",
    "g_results.set_xscale(\"log\", base=2)\n",
    "g_results.set_xlabel(\"Strides (Bytes)\")\n",
    "g_results.set_ylabel(\"Average Misses\")\n",
    "g_results.get_legend().set_title(\"Cache Size (Bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) By analyzing the obtained results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the size of the L1 data cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the block size adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Characterize the associativity set size adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Modeling the L2 Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Describe and justify the changes introduced in this program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Plot the variation of the average number of misses (Avg Misses) with the stride size, for each considered dimension of the L2 cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) By analyzing the obtained results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the size of the L2 cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the block size adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Characterize the associativity set size adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Profiling and Optimizing Data Cache Accesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Straightforward implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What is the total amount of memory that is required to accommodate each of these matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Fill the table with the obtained data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Evaluate the resulting L1 data cache Hit-Rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 First Optimization: Matrix transpose before multiplication [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Fill the table with the obtained data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Evaluate the resulting L1 data cache Hit-Rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Fill the table with the obtained data.\n",
    "\n",
    "Comment on the obtained results when including the matrix transposition in the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Compare the obtained results with those that were obtained for the straightforward implementation,\n",
    "by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Second Optimization: Blocked (tiled) matrix multiply [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) How many matrix elements can be accommodated in each cache line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Fill the table with the obtained data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Evaluate the resulting L1 data cache Hit-Rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Compare the obtained results with those that were obtained for the straightforward implementation,\n",
    "by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Compare the obtained results with those that were obtained for the matrix transpose implementation by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedup.If the obtained speedup is positive, but the difference of the resulting hit-rates is negative, how\n",
    "do you explain the performance improvement? (Hint: study the hit-rates of the L2 cache for both\n",
    "implementations;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Comparing results against the CPU specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have characterized the cache on your lab computer, you are going to compare it against the\n",
    "manufacturer’s specification. For this you can check the device’s datasheet, or make use of the command\n",
    "lscpu. Comment the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
