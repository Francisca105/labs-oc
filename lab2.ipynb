{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is the cache capacity of the computer you used (please write the workstation name)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "memo_num_accesses = {}\n",
    "\n",
    "\n",
    "def num_accesses(array_size):\n",
    "    \"\"\"Array size in KiB\"\"\"\n",
    "\n",
    "    key = array_size\n",
    "    if key in memo_num_accesses:\n",
    "        return memo_num_accesses[key]\n",
    "\n",
    "    array_size = array_size << 10\n",
    "\n",
    "    N_REPETITIONS = 100\n",
    "\n",
    "    STRIDE_MAX = 2\n",
    "\n",
    "    counter = 0\n",
    "    stride = 1\n",
    "\n",
    "    for stride in range(1, STRIDE_MAX, stride):\n",
    "\n",
    "        limit = array_size - stride + 1\n",
    "\n",
    "        for repeat in range(0, N_REPETITIONS * stride):\n",
    "            counter += (limit - 0) / stride\n",
    "\n",
    "    counter = int(counter)\n",
    "    memo_num_accesses[key] = counter\n",
    "\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(10):\n",
    "    df = pd.concat((df, pd.read_csv(f\"./data/spark{i:0>2}.tsv\", delimiter = \"\\t\")))\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = df.groupby([\"size\"], as_index = False).mean().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg[\"accesses\"] = df_avg[\"size\"].apply(lambda x: num_accesses(x >> 10))\n",
    "df_avg[\"mean_access_time\"] = df_avg[\"elapsed(s)\"] / df_avg[\"accesses\"]\n",
    "df_avg[\"mean_access_time (ns)\"] = df_avg[\"mean_access_time\"].apply(\n",
    "    lambda x: x * 10**9\n",
    ")\n",
    "df_avg[\"size (KiB)\"] = df_avg[\"size\"].apply(lambda x: x >> 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.sort_values(\"size\")[\n",
    "    [\"size (KiB)\", \"elapsed(s)\", \"accesses\", \"mean_access_time (ns)\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon analyzing the table above, which presents data collected from running the Spark program on the lab6p8 computer, we can determine that the cache capacity is 32KiB. This conclusion arises from the observation that the mean access time remains relatively constant for array sizes up to 32KiB (inclusive). However, once we reach 64KiB, the mean access time increases, suggesting a rise in the miss rate due to the L1 cache being filled. Consequently, it becomes clear that array sizes exceeding 32KiB no longer fit within the cache, resulting in longer access times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is the cache capacity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1 shows two groups of array sizes based on cache access times: one around 375 ns and the other around 500 ns. The first group likely includes arrays of size less than or equal to the cache capacity, indicating that these arrays can fully reside in the cache, resulting in lower access times. In contrast, the second group experiences higher execution times due to increased miss penalties as the arrays exceed cache capacity.\n",
    "\n",
    "The spike in reading and writing times beyond 64 KB confirms that this is the cache size limit, with the increase between 64 KB and 128 KB reflecting higher capacity misses. Thus, we conclude that the cache capacity corresponds to the maximum array size in the lower access time group: 64 KiB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the size of each cache block?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of a cache block can be determined by identifying the first stride where the access time stabilizes for the array sizes that do not fully fit in the cache (greater than 64 KB). We observe that the access time remains consistent for strides of 16 Bytes or larger, indicating that each accessed element corresponds to distinct cache blocks, resulting in a near 100% miss rate. Therefore, we can conclude that each cache block has a size of 16 Bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the L1 cache miss penalty time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the L1 cache miss penalty time, we compare the total execution times for different array sizes and access patterns. \n",
    "For array sizes that are smaller than the cache size, the miss rate is nearly 0%, resulting in an access time of approximately 375 ns. \n",
    "For larger arrays with a stride of 16 Bytes or greater, the access time increases to around 975 ns due to a nearly 100% miss rate.\n",
    "\n",
    "Therefore, the miss penalty can be determined by subtracting the lower access time from the higher one: 975 ns - 375 ns = 600 ns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3  Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Modeling the L1 Data Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What are the processor events that will be analyzed during its execution? Explain their meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the program's execution, the analyzed events will be L1 cache misses, which occur when data is not found in the L1 cache and access to the next memory level (L2 cache or main memory) is required. The cm1.c program tracks the PAPI_L1_DCM event, indicating \"L1 Data Cache Misses\". This analysis aims to quantify how often we attempt to retrieve data absent from the L1 cache throughout the program's runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Plot the variation of the average number of misses (Avg Misses) with the stride size, for each considered dimension of the L1 data cache (8kB, 16kB, 32kB and 64kB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_labels(val):\n",
    "    value = val.split(\"=\")[1]\n",
    "    return float(value) if \".\" in value else int(value)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    df = pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            pd.read_csv(\n",
    "                f\"./data/cm1_l1_{i:0>2}.tsv\",\n",
    "                delimiter = \"\\t\",\n",
    "                names = [\"cache_size\", \"stride\", \"avg_misses\", \"avg_time\"],\n",
    "                converters = {\n",
    "                    \"cache_size\": strip_labels,\n",
    "                    \"stride\": strip_labels,\n",
    "                    \"avg_misses\": strip_labels,\n",
    "                    \"avg_time\": strip_labels,\n",
    "                },\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df_avg = (\n",
    "    df.groupby([\"cache_size\", \"stride\"], as_index  =False).median().drop(\"index\", axis = 1)\n",
    ")\n",
    "\n",
    "print(df_avg)\n",
    "\n",
    "df_avg[\"cache_size\"] = df_avg[\"cache_size\"] // 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "sns.set_theme(context = \"poster\", style = \"whitegrid\")\n",
    "\n",
    "g_results = sns.lineplot(\n",
    "    data = df_avg, x = \"stride\", y = \"avg_misses\", hue = \"cache_size\" , palette = \"Set2\"\n",
    ")\n",
    "g_results.set_xscale(\"log\", base = 2)\n",
    "g_results.set_xlabel(\"Strides (Bytes)\")\n",
    "g_results.set_ylabel(\"Average Misses\")\n",
    "g_results.get_legend().set_title(\"Cache Size (kB)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) By analyzing the obtained results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the size of the L1 data cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the L1 cache size involves analyzing the plot of average misses versus array size. The blue line at 32kB shows that average misses remain at zero, indicating the cache can efficiently handle this size. A slight increase in misses at certain strides can be attributed to other data occupying the cache.\n",
    "\n",
    "Above 32kB, average miss rates spike significantly, suggesting that the array previously fit in the cache but exceeds its capacity at 64kB, leading to increased misses. Therefore, we can conclude that the L1 cache size is 32kB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the block size adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cache block size is  64 Bytes based on the analysis of the miss rate as strides vary. When strides are less than 64 Bytes = 2^6, the miss rate continues to increase, indicating that some accesses hit the cache and reside within the same block as previous accesses. Once the stride reaches 64 Bytes, the miss rate stabilizes at 1, suggesting that we are consistently loading new blocks into the cache, as the data being accessed is guaranteed not to be in the cache anymore. This stabilization occurs because a stride of 64 Bytes means that we skip over the entire block size, leading to sequential accesses to different blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Characterize the associativity set size adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the associativity set size involves examining how the miss rate behaves as we adjust the stride. Focusing on the largest cache size (indicated by the pink line at 64kB), we observe that when using a stride of 2^15, only two distinct blocks of data are accessed, leading to a near-zero miss rate, provided the cache has at least 2-way associativity.\n",
    "Continuing with this analysis for lower strides, we see that the miss rate remains close to zero at 2^14 and 2^13. This observation implies that the cache is at least 4-way or 8-way associative. However, when we test a stride of 2^12, the miss rate increases significantly, indicating that we have surpassed the associativity capacity of the cache.\n",
    "This leads to the conclusion that the associativity set size is 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Modeling the L2 Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Describe and justify the changes introduced in this program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Plot the variation of the average number of misses (Avg Misses) with the stride size, for each considered dimension of the L2 cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_labels(val):\n",
    "    value = val.split(\"=\")[1]\n",
    "    return float(value) if \".\" in value else int(value)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    df = pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            pd.read_csv(\n",
    "                f\"./data/cm1_l2_{i:0>2}.tsv\",\n",
    "                delimiter = \"\\t\",\n",
    "                names = [\"cache_size\", \"stride\", \"avg_misses\", \"avg_time\"],\n",
    "                converters = {\n",
    "                    \"cache_size\": strip_labels,\n",
    "                    \"stride\": strip_labels,\n",
    "                    \"avg_misses\": strip_labels,\n",
    "                    \"avg_time\": strip_labels,\n",
    "                },\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df_avg = (\n",
    "    df.groupby([\"cache_size\", \"stride\"], as_index = False).median().drop(\"index\", axis = 1)\n",
    ")\n",
    "\n",
    "print(df_avg)\n",
    "\n",
    "df_avg[\"cache_size\"] = df_avg[\"cache_size\"] // 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "sns.set_theme(context = \"poster\", style = \"whitegrid\")\n",
    "\n",
    "g_results = sns.lineplot(\n",
    "    data = df_avg, x = \"stride\", y = \"avg_misses\", hue = \"cache_size\" , palette = \"bright\"\n",
    ")\n",
    "g_results.set_xscale(\"log\", base = 2)\n",
    "g_results.set_xlabel(\"Strides (Bytes)\")\n",
    "g_results.set_ylabel(\"Average Misses\")\n",
    "g_results.get_legend().set_title(\"Cache Size (kB)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) By analyzing the obtained results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the size of the L2 cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the block size adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Characterize the associativity set size adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Profiling and Optimizing Data Cache Accesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Straightforward implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What is the total amount of memory that is required to accommodate each of these matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `unit16_t` occupies 2 Bytes in memory. A 512 x 512 matrix of `uint16_t` elements will require 512 x 512 x 2 Bytes = $(512^9)^2$ x 2 = $2^{19}$ Bytes = $(2^9)^{10}$ Bytes = 512KB. \n",
    "\n",
    "Therefore, the total memory required to accommodate two is 512KB x 2 = 1MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Fill the table with the obtained data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of L1 data cache misses: $135.352286$ x $10^6$ \\\n",
    "Total number of load / store instructions completed: $536.872118$ x $10^6$ (load instructions + store instructions) \\\n",
    "Total number of clock cycles: $656.882706$ x $10^6$ \\\n",
    "Elapsed time: $0.218961$ seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Evaluate the resulting L1 data cache Hit-Rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit-Rate = 1 - Miss-Rate = 1 - Misses/Accesses =  $1$ - ($135.352286$ x $10^6$  / $536.872118$ x $10^6$ ) $\\approx$ 0.747887 or $74.79\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 First Optimization: Matrix transpose before multiplication [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Fill the table with the obtained data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of L1 data cache misses: $4.219727$ x $10^6$ \\\n",
    "Total number of load / store instructions completed: $536.872076$ x $10^6$ (load instructions + store instructions) \\\n",
    "Total number of clock cycles: $535.792339$ x $10^6$ \\\n",
    "Elapsed time: $0.178598$ seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Evaluate the resulting L1 data cache Hit-Rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit-Rate = 1 - Miss-Rate = 1 - Misses/Accesses =  $1$ - ($4.219727$ x $10^6$  / $536.872076$ x $10^6$ ) $\\approx$ $0.992140$ or $99.21\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Fill the table with the obtained data.\n",
    "\n",
    "Comment on the obtained results when including the matrix transposition in the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of L1 data cache misses: $4.482571$ x $10^6$ \\\n",
    "Total number of load / store instructions completed: $537.396493$ x $10^6$ (load instructions + store instructions) \\\n",
    "Total number of clock cycles: $537.151077$ x $10^6$ \\\n",
    "Elapsed time: $0.179051$ seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit-Rate = 1 - Miss-Rate = 1 - Misses/Accesses =  $1$ - ($4.482571$ x $10^6$  / $537.396493$ x $10^6$ ) $\\approx$ $0.991659$ or $99.16\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon reviewing the results, it's clear that incorporating matrix transposition into the execution time has a minimal effect. This is because transposition, with its quadratic complexity $(O(^2))$, is far less computationally demanding compared to matrix multiplication, which has cubic complexity $(O(n^3))$. While the execution time increased slightly with the transposition step, the difference is so minor that it doesn’t meaningfully impact the overall results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Compare the obtained results with those that were obtained for the straightforward implementation,\n",
    "by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delta Hit Rate = HitRate mm2 - HitRate mm1: 0.991659 - 0.747887 = 0.243772 \\\n",
    "Speedup(#Clocks) = #Clocks mm1 / #Clocks mm2: 656.882706 / 537.151077 = 1.2229 \\\n",
    "Speedup(Time) = Time mm1 / Time mm2: 0.218961 / 0.179051 = 1.2229 \n",
    "\n",
    "The analysis reveal a significant 24.38% increase in hit rate, reflecting improved caching efficiency. his suggests that the optimization makes better use of caching, allowing more data accesses to be served by the faster L2 cache instead of the slower L3 cache or main memory, which considerably reduces the overall miss penalty.\n",
    "\n",
    "Despite these impressive gains, the achieved speedup is relatively small $\\approx$ 1.22. Additionally, the optimization requires more memory because it needs to store an extra NxN matrix in the main memory. For systems with limited memory, the performance benefits may not outweigh the extra memory needed, making this optimization less suitable in such cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Second Optimization: Blocked (tiled) matrix multiply [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) How many matrix elements can be accommodated in each cache line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Fill the table with the obtained data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Evaluate the resulting L1 data cache Hit-Rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Compare the obtained results with those that were obtained for the straightforward implementation,\n",
    "by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Compare the obtained results with those that were obtained for the matrix transpose implementation by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedup.If the obtained speedup is positive, but the difference of the resulting hit-rates is negative, how\n",
    "do you explain the performance improvement? (Hint: study the hit-rates of the L2 cache for both\n",
    "implementations;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Comparing results against the CPU specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have characterized the cache on your lab computer, you are going to compare it against the\n",
    "manufacturer’s specification. For this you can check the device’s datasheet, or make use of the command\n",
    "lscpu. Comment the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
